{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fbb218c-3c95-479d-87eb-b38ac4101ba9",
   "metadata": {},
   "source": [
    "# Group 1 Final Project Work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b79343-85ed-4a30-b48f-4475c77a98e1",
   "metadata": {},
   "source": [
    "#### Specific data on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3387b813-213e-4b8d-b13c-01d8e44ecc7e",
   "metadata": {},
   "source": [
    "### Maternal Health Risk Dataset Summary\n",
    "\n",
    "**Shape:** 808 records × 7 columns  \n",
    "\n",
    "**Columns:**\n",
    "- `Age`\n",
    "- `SystolicBP` (Systolic Blood Pressure)\n",
    "- `DiastolicBP` (Diastolic Blood Pressure)\n",
    "- `BS` (Blood Sugar level)\n",
    "- `BodyTemp` (Body Temperature, °F)\n",
    "- `HeartRate` (Heart Rate, bpm)\n",
    "- `RiskLevel` (Target: maternal health risk category)\n",
    "\n",
    "---\n",
    "\n",
    "#### First 5 Records\n",
    "| Age | SystolicBP | DiastolicBP | BS   | BodyTemp | HeartRate | RiskLevel  |\n",
    "|-----|------------|--------------|------|----------|-----------|------------|\n",
    "| 25  | 130        | 80           | 15.0 | 98.0     | 86        | high risk  |\n",
    "| 35  | 140        | 90           | 13.0 | 98.0     | 70        | high risk  |\n",
    "| 29  | 90         | 70           | 8.0  | 100.0    | 80        | high risk  |\n",
    "| 30  | 140        | 85           | 7.0  | 98.0     | 70        | high risk  |\n",
    "| 35  | 120        | 60           | 6.1  | 98.0     | 76        | low risk   |\n",
    "\n",
    "---\n",
    "\n",
    "#### Summary Statistics\n",
    "- **Age:** 10–70 years (mean = 30.6, std = 13.9)  \n",
    "- **SystolicBP:** 70–160 mmHg (mean = 113, std = 19.9)  \n",
    "- **DiastolicBP:** 49–100 mmHg (mean = 77.5, std = 14.8)  \n",
    "- **BS:** 6–19 mmol/L (mean = 9.26, std = 3.62)  \n",
    "- **BodyTemp:** 98–103 °F (mean = 98.6, std = 1.39)  \n",
    "- **HeartRate:** 7–90 bpm (mean = 74.3, std = 8.82)  \n",
    "\n",
    "---\n",
    "\n",
    "#### Target Variable: RiskLevel\n",
    "- **Low risk:** 478 records (~59.2%)  \n",
    "- **High risk:** 330 records (~40.8%)  \n",
    "- **Medium risk:** Not present in this dataset version  \n",
    "\n",
    " Note: The dataset is binary-labeled (low vs. high risk), so if a 3-class model (low/mid/high) is needed, additional data preprocessing or augmentation may be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ac998-df87-4fa8-a23c-c32dd6250ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T00:29:58.488110Z",
     "iopub.status.busy": "2025-09-20T00:29:58.487852Z",
     "iopub.status.idle": "2025-09-20T00:29:58.491576Z",
     "shell.execute_reply": "2025-09-20T00:29:58.490728Z",
     "shell.execute_reply.started": "2025-09-20T00:29:58.488088Z"
    }
   },
   "source": [
    "### Week 3 - Training and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d938a2-5f7a-4a04-b9a7-c4dd14f5aa77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T00:33:39.970066Z",
     "iopub.status.busy": "2025-09-20T00:33:39.969690Z",
     "iopub.status.idle": "2025-09-20T00:33:39.973857Z",
     "shell.execute_reply": "2025-09-20T00:33:39.972733Z",
     "shell.execute_reply.started": "2025-09-20T00:33:39.970039Z"
    }
   },
   "source": [
    "#### EDA --> feature engineering --> stratified splits (40/10/10/40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204e533a-2bf3-413f-b03d-2bd34a912eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T00:35:06.423327Z",
     "iopub.status.busy": "2025-09-20T00:35:06.422916Z",
     "iopub.status.idle": "2025-09-20T00:35:09.462799Z",
     "shell.execute_reply": "2025-09-20T00:35:09.462038Z",
     "shell.execute_reply.started": "2025-09-20T00:35:06.423302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1464/12418796.py:32: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot([df['SystolicBP'], df['DiastolicBP']], labels=['SystolicBP','DiastolicBP'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Files written to: week3_outputs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATA_PATH = Path(\"Maternal_Risk.csv\") \n",
    "OUT_DIR = Path(\"./week3_outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "assert 'RiskLevel' in df.columns, \"Expected target column 'RiskLevel'\"\n",
    "\n",
    "# Basic EDA (shape, dtypes, nulls, class balance)\n",
    "eda = {\n",
    "    \"rows\": int(df.shape[0]),\n",
    "    \"cols\": int(df.shape[1]),\n",
    "    \"dtypes\": {c: str(t) for c, t in df.dtypes.items()},\n",
    "    \"missing\": df.isna().sum().to_dict(),\n",
    "    \"class_counts\": df['RiskLevel'].value_counts().to_dict(),\n",
    "}\n",
    "pd.Series(eda[\"class_counts\"], name=\"class_counts\")\n",
    "\n",
    "# Quick EDA charts (matplotlib defaults; no custom colors)\n",
    "df['RiskLevel'].value_counts().plot(kind='bar'); plt.title(\"Class Distribution\"); plt.tight_layout()\n",
    "plt.savefig(OUT_DIR/\"chart_class_distribution.png\", dpi=150); plt.clf()\n",
    "\n",
    "df['Age'].plot(kind='hist', bins=20); plt.title(\"Age Distribution\"); plt.tight_layout()\n",
    "plt.savefig(OUT_DIR/\"chart_age_hist.png\", dpi=150); plt.clf()\n",
    "\n",
    "plt.boxplot([df['SystolicBP'], df['DiastolicBP']], labels=['SystolicBP','DiastolicBP'])\n",
    "plt.title(\"Blood Pressure Boxplots\"); plt.tight_layout()\n",
    "plt.savefig(OUT_DIR/\"chart_bp_box.png\", dpi=150); plt.clf()\n",
    "\n",
    "corr = df.select_dtypes(include=np.number).corr()\n",
    "plt.imshow(corr, interpolation='nearest'); plt.xticks(range(len(corr)), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(corr)), corr.columns); plt.colorbar(); plt.title(\"Correlation Heatmap\"); plt.tight_layout()\n",
    "plt.savefig(OUT_DIR/\"chart_corr_heatmap.png\", dpi=150); plt.clf()\n",
    "\n",
    "# Feature engineering (keep raw + engineered)\n",
    "X = df.copy()\n",
    "X['PulsePressure']  = X['SystolicBP'] - X['DiastolicBP']\n",
    "X['SBP_to_DBP']     = X['SystolicBP'] / (X['DiastolicBP'].replace(0, np.nan))\n",
    "X['Fever']          = (X['BodyTemp'] > 99.5).astype(int)\n",
    "X['Tachycardia']    = (X['HeartRate'] >= 100).astype(int)\n",
    "X['HypertensionFlag']= ((X['SystolicBP'] >= 140) | (X['DiastolicBP'] >= 90)).astype(int)\n",
    "\n",
    "# optional z-scaling for continuous features\n",
    "cont = ['Age','SystolicBP','DiastolicBP','BS','BodyTemp','HeartRate','PulsePressure','SBP_to_DBP']\n",
    "X[[f\"z_{c}\" for c in cont]] = StandardScaler().fit_transform(X[cont])\n",
    "\n",
    "# Encode label (binary in your file)\n",
    "label_map = {'low risk':0, 'high risk':1}\n",
    "y = X['RiskLevel'].map(label_map) if set(df['RiskLevel'].unique())==set(label_map) \\\n",
    "    else X['RiskLevel'].astype('category').cat.codes\n",
    "X = X.drop(columns=['RiskLevel'])\n",
    "pd.Series(label_map).to_json(OUT_DIR/\"label_map.json\")\n",
    "\n",
    "# Stratified splits: prod 40%, then remaining 60% -> train 40% (of full),\n",
    "#    val 10%, test 10% (of full)\n",
    "X_temp, X_prod, y_temp, y_prod = train_test_split(X, y, test_size=0.40, random_state=42, stratify=y)\n",
    "X_train, X_rem, y_train, y_rem  = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)\n",
    "X_val, X_test, y_val, y_test    = train_test_split(X_rem, y_rem, test_size=0.5, random_state=42, stratify=y_rem)\n",
    "\n",
    "def _save(name, Xd, yd):\n",
    "    out = Xd.copy()\n",
    "    out['label'] = yd.values\n",
    "    out.to_csv(OUT_DIR/f\"{name}.csv\", index=False)\n",
    "    return out\n",
    "\n",
    "train = _save(\"train\", X_train, y_train)\n",
    "val   = _save(\"val\",   X_val,   y_val)\n",
    "test  = _save(\"test\",  X_test,  y_test)\n",
    "prod  = _save(\"production\", X_prod, y_prod)\n",
    "\n",
    "# 7) Save engineered full for reference + tracker\n",
    "df_engineered = pd.concat([X, y.rename('label')], axis=1)\n",
    "df_engineered.to_csv(OUT_DIR/\"maternal_features_full.csv\", index=False)\n",
    "\n",
    "with open(OUT_DIR/\"eda_summary.json\",\"w\") as f:\n",
    "    import json; json.dump(eda, f, indent=2)\n",
    "\n",
    "print(\"Done. Files written to:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d4adc-f878-43ba-8088-6b1ae27302c2",
   "metadata": {},
   "source": [
    "#### Upload splits to S3 (so Feature Store can ingest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8831eee7-cacf-4d1d-9ab8-722e439b677d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-20T00:36:51.798150Z",
     "iopub.status.busy": "2025-09-20T00:36:51.797862Z",
     "iopub.status.idle": "2025-09-20T00:36:51.801142Z",
     "shell.execute_reply": "2025-09-20T00:36:51.800529Z",
     "shell.execute_reply.started": "2025-09-20T00:36:51.798128Z"
    }
   },
   "outputs": [],
   "source": [
    "# In out Studio: to set bucket/prefix and run this\n",
    "import boto3, os\n",
    "bucket = \"<OUR_BUCKET>\"  # To be set later\n",
    "prefix = \"aai540/maternal_risk/week3\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "for fname in [\"train.csv\",\"val.csv\",\"test.csv\",\"production.csv\",\"maternal_features_full.csv\",\"label_map.json\",\"eda_summary.json\"]:\n",
    "    s3.upload_file(f\"./week3_outputs/{fname}\", bucket, f\"{prefix}/{fname}\")\n",
    "    print(f\"Uploaded s3://{bucket}/{prefix}/{fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53d720b-3cbf-4645-81e5-cda60c4bf8c6",
   "metadata": {},
   "source": [
    "#### Initialize Feature Store & design feature groups (train/val/batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b953f3-132d-4faf-9042-56c570bb7df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal excerpt (full file is provided above)\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "\n",
    "# Create three offline-only feature groups and ingest your CSVs\n",
    "fg_train = FeatureGroup(name=\"mhr_train_fg\", sagemaker_session=Session())\n",
    "# fg_train.load_feature_definitions(data_frame=train_df); fg_train.create(...); fg_train.ingest(...)\n",
    "\n",
    "# Repeat for mhr_val_fg and mhr_batch_fg (production)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
